{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d743fff",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 21:48:19.743435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746582499.773748  259472 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746582499.782964  259472 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746582499.826803  259472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746582499.826858  259472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746582499.826859  259472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746582499.826860  259472 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from functools import cache\n",
    "from os import listdir\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import combinations\n",
    "\n",
    "from typing import Any, List, Tuple\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import dataclasses\n",
    "\n",
    "\n",
    "# |Set root for GPUDrive import\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from traitlets import default\n",
    "\n",
    "# Set working directory to the base directory 'gpudrive'\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive-CoDec':\n",
    "    working_dir = working_dir.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "sys.path.append(str(working_dir))\n",
    "\n",
    "\n",
    "# |GPUDrive imports\n",
    "from gpudrive.utils.config import load_config\n",
    "from examples.CoDec_Research.code.simulation.construal_main import generate_baseline_data, generate_selected_construal_traj, \\\n",
    "                                                                    get_constral_heurisrtic_values, generate_all_construal_trajnval\n",
    "from examples.CoDec_Research.code.gpuDrive_utils import get_gpuDrive_vars\n",
    "from examples.CoDec_Research.code.analysis.evaluate_construal_actions import evaluate_construals, get_best_construals_likelihood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d02052",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Parameters for Inference ###\n",
    "heuristic_params = {\"ego_distance\": 0.5} # Parameters for weighing the heuristics\n",
    "\n",
    "### Specify Environment Configuration ###\n",
    "\n",
    "# |Location to store (and find pre-computed) simulation results\n",
    "simulation_results_path = \"examples/CoDec_Research/results/simulation_results/\"\n",
    "simulation_results_files = [simulation_results_path+fl_name for fl_name in listdir(simulation_results_path)]\n",
    "\n",
    "# |Location to store simulation results\n",
    "out_dir = \"examples/CoDec_Research/results/simulation_results/\"\n",
    "\n",
    "# |Model Config (on which model was trained)\n",
    "training_config = load_config(\"examples/experimental/config/reliable_agents_params\")\n",
    "\n",
    "# |Set scenario path\n",
    "dataset_path = 'data/processed/construal'\n",
    "\n",
    "# |Set simulator config\n",
    "max_agents = training_config.max_controlled_agents   # Get total vehicle count\n",
    "num_parallel_envs = 2\n",
    "total_envs = 4\n",
    "device = \"cpu\" # cpu just because we're in a notebook\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# |Set construal config\n",
    "construal_size = 1\n",
    "observed_agents_count = max_agents - 1      # Agents observed except self (used for vector sizes)\n",
    "sample_size = 1                             # Number of samples to calculate expected utility of a construal\n",
    "\n",
    "# |Other changes to variables\n",
    "training_config.max_controlled_agents = 1    # Control only the first vehicle in the environment\n",
    "total_envs = min(total_envs, len(listdir(dataset_path)))\n",
    "\n",
    "\n",
    "### Instantiate Variables ###\n",
    "\n",
    "env_config, train_loader, env, env_multi_agent, sim_agent = get_gpuDrive_vars(\n",
    "                                                                                training_config = training_config,\n",
    "                                                                                device = device,\n",
    "                                                                                num_parallel_envs = num_parallel_envs,\n",
    "                                                                                dataset_path = dataset_path,\n",
    "                                                                                max_agents = max_agents,\n",
    "                                                                                total_envs = total_envs,\n",
    "                                                                                sim_agent_path= \"daphne-cornelisse/policy_S10_000_02_27\",\n",
    "                                                                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9a63322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  8.82it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### Select Construals for Baseline Data ###\n",
    "scene_constr_dict = None\n",
    "\n",
    "#2# |Generate Construal Execution Values through simulator sampling\n",
    "default_values = None\n",
    "\n",
    "#2# |Check if saved data is available\n",
    "for srFile in simulation_results_files:\n",
    "    if \"construal_vals\" in srFile:\n",
    "        with open(srFile, 'rb') as opn_file:\n",
    "            default_values = pickle.load(opn_file)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "if default_values is None:\n",
    "    default_values, traj_obs, ground_truth = generate_all_construal_trajnval(out_dir=out_dir,\n",
    "                                                                                sim_agent=sim_agent,\n",
    "                                                                                observed_agents_count=observed_agents_count,\n",
    "                                                                                construal_size=construal_size,\n",
    "                                                                                num_parallel_envs=num_parallel_envs,\n",
    "                                                                                max_agents=max_agents,\n",
    "                                                                                sample_size=sample_size,\n",
    "                                                                                device=device,\n",
    "                                                                                train_loader=train_loader,\n",
    "                                                                                env=env,\n",
    "                                                                                env_multi_agent=env_multi_agent,\n",
    "                                                                                generate_animations=False)\n",
    "\n",
    "#2# |Generate Construal Heuristic Values (Heuristic 1: Distance from ego)\n",
    "heuristic_values = get_constral_heurisrtic_values(env, train_loader, default_values, heuristic_params=heuristic_params)\n",
    "\n",
    "#2# |Sample from construal values\n",
    "def sample_construals(heuristic_values: dict, sample_count: int) -> dict:\n",
    "    \"\"\"\n",
    "    Sample construals based on heuristic values.\n",
    "    \"\"\"\n",
    "    sampled_construals = {}\n",
    "    for scene_name, construal_info in heuristic_values.items():\n",
    "        constr_indices, constr_values = zip(*construal_info.items())\n",
    "        constr_values_softmax = torch.nn.functional.softmax(torch.tensor(constr_values), dim=0)\n",
    "        sampled_indices = torch.multinomial(constr_values_softmax, num_samples=sample_count, \\\n",
    "                                                            replacement=False).tolist()\n",
    "        sampled_construals[scene_name] = {constr_indices[i]: constr_values[i] for i in sampled_indices}\n",
    "\n",
    "    return sampled_construals\n",
    "\n",
    "scene_constr_dict = sample_construals(heuristic_values, sample_count=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31c5a693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfrecord-00101-of-01000_71': {(0,): np.float64(1.0),\n",
       "  (1,): np.float64(0.9548024362736818),\n",
       "  (5,): np.float64(0.629016666487872),\n",
       "  (9,): np.float64(0.5742991115584066),\n",
       "  (10,): np.float64(0.9042478755727865),\n",
       "  (42,): np.float64(0.613054930528357),\n",
       "  (43,): np.float64(0.5385952434420198),\n",
       "  (0, 1, 5, 9, 10, 42, 43): np.float64(0.7448594662661605)},\n",
       " 'tfrecord-00117-of-01000_240': {(0,): np.float64(1.0),\n",
       "  (1,): np.float64(0.7215077800397827),\n",
       "  (2,): np.float64(0.5381755943648112),\n",
       "  (3,): np.float64(0.6078264890552836),\n",
       "  (4,): np.float64(0.9401724415680937),\n",
       "  (5,): np.float64(0.700456969135634),\n",
       "  (7,): np.float64(0.9385660133622136),\n",
       "  (8,): np.float64(0.6320838417348973),\n",
       "  (9,): np.float64(0.744795752946394),\n",
       "  (10,): np.float64(0.6767799318279193),\n",
       "  (11,): np.float64(0.7732606874164518),\n",
       "  (12,): np.float64(0.827249699708235),\n",
       "  (13,): np.float64(0.7074301356948892),\n",
       "  (14,): np.float64(-0.20800941945850976),\n",
       "  (15,): np.float64(-0.19140329129862552),\n",
       "  (16,): np.float64(0.5780489844050494),\n",
       "  (17,): np.float64(0.5),\n",
       "  (0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17): np.float64(0.7345259770883835)},\n",
       " 'tfrecord-00143-of-01000_179': {(0,): np.float64(1.0),\n",
       "  (1,): np.float64(0.874512414001905),\n",
       "  (2,): np.float64(0.9566572884744492),\n",
       "  (3,): np.float64(0.9319287759714698),\n",
       "  (4,): np.float64(0.9609614072056583),\n",
       "  (5,): np.float64(0.8947167899653797),\n",
       "  (6,): np.float64(0.8609190761374382),\n",
       "  (7,): np.float64(0.8779299146399948),\n",
       "  (8,): np.float64(0.8690504112133746),\n",
       "  (9,): np.float64(0.8009872483293122),\n",
       "  (10,): np.float64(0.8183985869213019),\n",
       "  (11,): np.float64(0.8101012236363122),\n",
       "  (12,): np.float64(0.8675016266239778),\n",
       "  (13,): np.float64(0.8993947570190729),\n",
       "  (14,): np.float64(0.8890687447519268),\n",
       "  (15,): np.float64(-0.16867538826614684),\n",
       "  (16,): np.float64(0.9093628145668092),\n",
       "  (17,): np.float64(0.8822719031157411),\n",
       "  (18,): np.float64(0.8438464678625532),\n",
       "  (19,): np.float64(-0.1672827742287926),\n",
       "  (20,): np.float64(0.8249419354633548),\n",
       "  (0,\n",
       "   1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20): np.float64(0.8779330106383377)},\n",
       " 'tfrecord-00144-of-01000_130': {(0,): np.float64(1.0),\n",
       "  (7,): np.float64(0.9128845467943143),\n",
       "  (59,): np.float64(0.8713387289404813),\n",
       "  (0, 7, 59): np.float64(0.9280744252449319)}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heuristic_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad09e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate Synthetic Ground Truth for Selected Construals (Baseline Data on Which to Perform Inference) ###\n",
    "state_action_pairs = None\n",
    "\n",
    "# |Check if saved data is available\n",
    "for srFile in simulation_results_files:\n",
    "    if \"baseline_state_action_pairs\" not in srFile:\n",
    "        continue\n",
    "    with open(srFile, 'rb') as opn_file:\n",
    "        state_action_pairs = pickle.load(opn_file)\n",
    "\n",
    "if state_action_pairs is None:\n",
    "    state_action_pairs = generate_baseline_data(out_dir=out_dir,\n",
    "                                                sim_agent=sim_agent,\n",
    "                                                num_parallel_envs=num_parallel_envs,\n",
    "                                                max_agents=max_agents,\n",
    "                                                sample_size=1,\n",
    "                                                device=device,\n",
    "                                                train_loader=train_loader,\n",
    "                                                env=env,\n",
    "                                                env_multi_agent=env_multi_agent,\n",
    "                                                observed_agents_count=observed_agents_count,\n",
    "                                                construal_size=construal_size,\n",
    "                                                selected_construals=scene_constr_dict,\n",
    "                                                generate_animations=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d79a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute Construal Log Likelihoods ###\n",
    "construal_action_likelihoods = None\n",
    "\n",
    "# |Check if saved data is available\n",
    "for srFile in simulation_results_files:\n",
    "    if \"log_likelihood_measures\" not in srFile:\n",
    "        continue\n",
    "    with open(srFile, 'rb') as opn_file:\n",
    "        construal_action_likelihoods = pickle.load(opn_file)\n",
    "\n",
    "if construal_action_likelihoods is None:\n",
    "    construal_action_likelihoods = evaluate_construals(state_action_pairs, construal_size, sim_agent, out_dir, device=device)\n",
    "\n",
    "# |Clear memory for large variable, once it has served its purpose\n",
    "# del state_action_pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1a067fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Sanity Check ###\n",
    "scene_constr_dict = None\n",
    "scene_constr_diff_dict = None\n",
    "\n",
    "# |Check if saved data is available\n",
    "for srFile in simulation_results_files:\n",
    "    if \"highest_construal_dict_log_likelihood_diff\" in srFile:\n",
    "        with open(srFile, 'rb') as opn_file:\n",
    "            scene_constr_diff_dict = pickle.load(opn_file)\n",
    "    if \"highest_construal_dict_log_likelihood\" in srFile:\n",
    "        with open(srFile, 'rb') as opn_file:\n",
    "            scene_constr_dict = pickle.load(opn_file)\n",
    "\n",
    "if scene_constr_dict is None:\n",
    "    scene_constr_dict = get_best_construals_likelihood(construal_action_likelihoods, out_dir)\n",
    "if scene_constr_diff_dict is None:\n",
    "    scene_constr_diff_dict = get_best_construals_likelihood(construal_action_likelihoods, out_dir, likelihood_key=\"log_likelihood_diff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93f35f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene: tfrecord-00101-of-01000_71\n",
      "{((10,), (0, 1, 5, 9, 10, 42, 43), 0): tensor(45.0291, requires_grad=True), ((10,), (1,), 0): tensor(46.5550, requires_grad=True), ((10,), (5,), 0): tensor(53.8457, requires_grad=True), ((10,), (10,), 0): tensor(58.1080, requires_grad=True), ((10,), (0,), 0): tensor(58.2338, requires_grad=True), ((10,), (42,), 0): tensor(58.2338, requires_grad=True), ((10,), (43,), 0): tensor(58.2338, requires_grad=True), ((10,), (9,), 0): tensor(58.5760, requires_grad=True)}\n",
      "{((0, 1, 5, 9, 10, 42, 43), (0, 1, 5, 9, 10, 42, 43), 0): tensor(40.8187, requires_grad=True), ((0, 1, 5, 9, 10, 42, 43), (1,), 0): tensor(42.0083, requires_grad=True), ((0, 1, 5, 9, 10, 42, 43), (5,), 0): tensor(57.5896, requires_grad=True), ((0, 1, 5, 9, 10, 42, 43), (10,), 0): tensor(61.6216, requires_grad=True), ((0, 1, 5, 9, 10, 42, 43), (0,), 0): tensor(61.6605, requires_grad=True), ((0, 1, 5, 9, 10, 42, 43), (42,), 0): tensor(61.6605, requires_grad=True), ((0, 1, 5, 9, 10, 42, 43), (43,), 0): tensor(61.6605, requires_grad=True), ((0, 1, 5, 9, 10, 42, 43), (9,), 0): tensor(61.8911, requires_grad=True)}\n",
      "Scene: tfrecord-00117-of-01000_240\n",
      "{((9,), (1,), 0): tensor(93.3639, requires_grad=True), ((9,), (9,), 0): tensor(97.6725, requires_grad=True), ((9,), (8,), 0): tensor(98.5824, requires_grad=True), ((9,), (7,), 0): tensor(108.5594, requires_grad=True), ((9,), (3,), 0): tensor(109.4964, requires_grad=True), ((9,), (10,), 0): tensor(117.5002, requires_grad=True), ((9,), (5,), 0): tensor(117.9391, requires_grad=True), ((9,), (12,), 0): tensor(118.2717, requires_grad=True), ((9,), (0,), 0): tensor(124.6734, requires_grad=True), ((9,), (13,), 0): tensor(124.6734, requires_grad=True), ((9,), (14,), 0): tensor(124.6734, requires_grad=True), ((9,), (15,), 0): tensor(124.6734, requires_grad=True), ((9,), (16,), 0): tensor(124.6734, requires_grad=True), ((9,), (17,), 0): tensor(124.6734, requires_grad=True), ((9,), (4,), 0): tensor(128.9052, requires_grad=True), ((9,), (11,), 0): tensor(132.0465, requires_grad=True), ((9,), (2,), 0): tensor(152.7114, requires_grad=True), ((9,), (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), 0): tensor(173.6043, requires_grad=True)}\n",
      "{((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), 0): tensor(111.6321, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (3,), 0): tensor(139.8562, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (2,), 0): tensor(142.0697, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (11,), 0): tensor(149.4312, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (1,), 0): tensor(152.8385, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (4,), 0): tensor(153.4909, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (12,), 0): tensor(158.8468, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (9,), 0): tensor(160.1133, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (10,), 0): tensor(161.2884, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (0,), 0): tensor(164.0152, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (13,), 0): tensor(164.0152, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (14,), 0): tensor(164.0152, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (15,), 0): tensor(164.0152, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (16,), 0): tensor(164.0152, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (17,), 0): tensor(164.0152, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (7,), 0): tensor(164.8601, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (5,), 0): tensor(165.7660, requires_grad=True), ((0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17), (8,), 0): tensor(167.2537, requires_grad=True)}\n",
      "Scene: tfrecord-00143-of-01000_179\n",
      "{((3,), (10,), 0): tensor(92.6859, requires_grad=True), ((3,), (11,), 0): tensor(92.8368, requires_grad=True), ((3,), (8,), 0): tensor(93.1489, requires_grad=True), ((3,), (9,), 0): tensor(93.1831, requires_grad=True), ((3,), (7,), 0): tensor(93.4578, requires_grad=True), ((3,), (12,), 0): tensor(94.1319, requires_grad=True), ((3,), (3,), 0): tensor(95.8491, requires_grad=True), ((3,), (4,), 0): tensor(100.0839, requires_grad=True), ((3,), (6,), 0): tensor(101.0934, requires_grad=True), ((3,), (5,), 0): tensor(102.8558, requires_grad=True), ((3,), (2,), 0): tensor(141.0490, requires_grad=True), ((3,), (13,), 0): tensor(190.0022, requires_grad=True), ((3,), (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20), 0): tensor(219.4022, requires_grad=True), ((3,), (0,), 0): tensor(237.8370, requires_grad=True), ((3,), (14,), 0): tensor(237.8370, requires_grad=True), ((3,), (15,), 0): tensor(237.8370, requires_grad=True), ((3,), (16,), 0): tensor(237.8370, requires_grad=True), ((3,), (17,), 0): tensor(237.8370, requires_grad=True), ((3,), (18,), 0): tensor(237.8370, requires_grad=True), ((3,), (19,), 0): tensor(237.8370, requires_grad=True), ((3,), (20,), 0): tensor(237.8370, requires_grad=True), ((3,), (1,), 0): tensor(241.9509, requires_grad=True)}\n",
      "{((14,), (0,), 0): tensor(81.7276, requires_grad=True), ((14,), (14,), 0): tensor(81.7276, requires_grad=True), ((14,), (15,), 0): tensor(81.7276, requires_grad=True), ((14,), (16,), 0): tensor(81.7276, requires_grad=True), ((14,), (17,), 0): tensor(81.7276, requires_grad=True), ((14,), (18,), 0): tensor(81.7276, requires_grad=True), ((14,), (19,), 0): tensor(81.7276, requires_grad=True), ((14,), (20,), 0): tensor(81.7276, requires_grad=True), ((14,), (13,), 0): tensor(102.5862, requires_grad=True), ((14,), (1,), 0): tensor(115.3205, requires_grad=True), ((14,), (2,), 0): tensor(145.0312, requires_grad=True), ((14,), (12,), 0): tensor(148.1768, requires_grad=True), ((14,), (8,), 0): tensor(149.8349, requires_grad=True), ((14,), (9,), 0): tensor(149.9332, requires_grad=True), ((14,), (11,), 0): tensor(150.4833, requires_grad=True), ((14,), (10,), 0): tensor(150.9861, requires_grad=True), ((14,), (7,), 0): tensor(152.0642, requires_grad=True), ((14,), (3,), 0): tensor(157.3626, requires_grad=True), ((14,), (6,), 0): tensor(159.2243, requires_grad=True), ((14,), (4,), 0): tensor(161.2445, requires_grad=True), ((14,), (5,), 0): tensor(161.6890, requires_grad=True), ((14,), (0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20), 0): tensor(186.7816, requires_grad=True)}\n",
      "Scene: tfrecord-00144-of-01000_130\n",
      "{((0,), (7,), 0): tensor(47.1964, requires_grad=True), ((0,), (0, 7, 59), 0): tensor(47.1964, requires_grad=True), ((0,), (0,), 0): tensor(47.4115, requires_grad=True), ((0,), (59,), 0): tensor(47.4115, requires_grad=True)}\n",
      "{((0, 7, 59), (7,), 0): tensor(47.2258, requires_grad=True), ((0, 7, 59), (0, 7, 59), 0): tensor(47.2258, requires_grad=True), ((0, 7, 59), (0,), 0): tensor(47.7254, requires_grad=True), ((0, 7, 59), (59,), 0): tensor(47.7254, requires_grad=True)}\n"
     ]
    }
   ],
   "source": [
    "for scene_name_, scene_info_ in construal_action_likelihoods.items():\n",
    "    print(f\"Scene: {scene_name_}\")\n",
    "    for base_construal_name_, base_construal_info_ in scene_info_.items():\n",
    "        print_dict = {}\n",
    "        for test_construal_name_, test_construal_info_ in base_construal_info_.items():\n",
    "            for sample_num_, sample_info_ in test_construal_info_.items():\n",
    "                # print_dict.update({(base_construal_name_, test_construal_name_, sample_num_): abs(sample_info_['log_likelihood_diff'])})\n",
    "                print_dict.update({(base_construal_name_, test_construal_name_, sample_num_): sample_info_['log_likelihood']})\n",
    "        print(dict(sorted(print_dict.items(), key=lambda item: item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6eaaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  7.30it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  7.75it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  8.23it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  7.44it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  7.56it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  8.05it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  7.91it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  8.04it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  8.25it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  7.72it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 2/2 [00:00<00:00,  8.80it/s]\n"
     ]
    }
   ],
   "source": [
    "### Inference Logic ###\n",
    "\n",
    "# |Get probability of lambda values\n",
    "get_constral_heurisrtic_values_partial = partial(get_constral_heurisrtic_values, env=env, \n",
    "                                                 train_loader=train_loader, default_values=default_values)\n",
    "p_lambda = {}\n",
    "for curr_lambda in np.linspace(0,1,11):\n",
    "    curr_lambda = curr_lambda.item()\n",
    "    heuristic_params = {\"ego_distance\": curr_lambda}\n",
    "    curr_heuristic_values = get_constral_heurisrtic_values_partial(heuristic_params=heuristic_params)\n",
    "    p_lambda[curr_lambda] = {}\n",
    "    for scene_name, scene_info in curr_heuristic_values.items():\n",
    "        p_lambda[curr_lambda][scene_name] = {}\n",
    "        sampled_construals = construal_action_likelihoods[scene_name]\n",
    "        for base_construal, construal_info in sampled_construals.items():\n",
    "            curr_p_lambda = []\n",
    "            for construal_indx, construal_heur_value in scene_info.items():\n",
    "                sample_num = 0\n",
    "                p_a = -1*construal_info[construal_indx][sample_num]['log_likelihood'].item()\n",
    "                curr_p_lambda.append(( torch.exp(torch.tensor(p_a))*construal_heur_value.item() ).item())\n",
    "            p_lambda[curr_lambda][scene_name][base_construal] = sum(curr_p_lambda)/len(curr_p_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a63fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: {'tfrecord-00101-of-01000_71': {(10,): 4.231859807463398e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 3.0545672030782197e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 1.6047202913959698e-42,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 9.744119957836842e-42,\n",
       "   (14,): 8.747277200461541e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.8752489111303885e-21,\n",
       "   (0, 7, 59): 2.4832118498845487e-21}},\n",
       " 0.1: {'tfrecord-00101-of-01000_71': {(10,): 4.04763485194575e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 2.9286250032032814e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 1.5152707394232354e-42,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 9.419655667960904e-42,\n",
       "   (14,): 8.459647309532444e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.8334202495177537e-21,\n",
       "   (0, 7, 59): 2.4465675064103795e-21}},\n",
       " 0.2: {'tfrecord-00101-of-01000_71': {(10,): 3.863410300373034e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 2.802682932575314e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 1.4258211874505014e-42,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 9.095318768854452e-42,\n",
       "   (14,): 8.17201741860335e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.791591587905119e-21,\n",
       "   (0, 7, 59): 2.409923263910406e-21}},\n",
       " 0.30000000000000004: {'tfrecord-00101-of-01000_71': {(10,): 3.6791853449050755e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 2.676740732700375e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 1.3363716354777672e-42,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 8.770854478978514e-42,\n",
       "   (14,): 7.884387863985886e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.749762926292484e-21,\n",
       "   (0, 7, 59): 2.373278869949139e-21}},\n",
       " 0.4: {'tfrecord-00101-of-01000_71': {(10,): 3.494960641871451e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 2.5507987266958923e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 1.2469999334197178e-42,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 8.446517579872061e-42,\n",
       "   (14,): 7.596757881335436e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.7079343151669472e-21,\n",
       "   (0, 7, 59): 2.3366345769620677e-21}},\n",
       " 0.5: {'tfrecord-00101-of-01000_71': {(10,): 3.310735686377685e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 2.4248565268209545e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 1.1576282313616683e-42,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 8.122180680765608e-42,\n",
       "   (14,): 7.309128071936434e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.6661056030672145e-21,\n",
       "   (0, 7, 59): 2.2999902839749964e-21}},\n",
       " 0.6000000000000001: {'tfrecord-00101-of-01000_71': {(10,): 3.1265111348057395e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 2.2989144561929864e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 1.0681008294742494e-42,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 7.797716390889671e-42,\n",
       "   (14,): 7.021498364450047e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.6242769414545797e-21,\n",
       "   (0, 7, 59): 2.2633459405008272e-21}},\n",
       " 0.7000000000000001: {'tfrecord-00101-of-01000_71': {(10,): 2.9422861793119734e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 2.172972256318052e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 9.786512775015153e-43,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 7.473379491783217e-42,\n",
       "   (14,): 6.733868453138428e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.582448330329043e-21,\n",
       "   (0, 7, 59): 2.226701622270207e-21}},\n",
       " 0.8: {'tfrecord-00101-of-01000_71': {(10,): 2.758061223843437e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 2.0470300564431134e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 8.892017255287811e-43,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 7.148978897292022e-42,\n",
       "   (14,): 6.44623880679961e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.540619668716408e-21,\n",
       "   (0, 7, 59): 2.1900573292831357e-21}},\n",
       " 0.9: {'tfrecord-00101-of-01000_71': {(10,): 2.5738365207857384e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 1.9210879858151458e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 7.997521735560469e-43,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 6.824578302800827e-42,\n",
       "   (14,): 6.158608997400607e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.4987910071037733e-21,\n",
       "   (0, 7, 59): 2.1534129605654175e-21}},\n",
       " 1.0: {'tfrecord-00101-of-01000_71': {(10,): 2.3896117672528826e-21,\n",
       "   (0, 1, 5, 9, 10, 42, 43): 1.795145915187178e-19},\n",
       "  'tfrecord-00117-of-01000_240': {(9,): 7.103804714979976e-43,\n",
       "   (0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17): 0.0},\n",
       "  'tfrecord-00143-of-01000_179': {(3,): 6.50011401292489e-42,\n",
       "   (14,): 5.8709791880016046e-37},\n",
       "  'tfrecord-00144-of-01000_130': {(0,): 2.4569623454911385e-21,\n",
       "   (0, 7, 59): 2.1167686170912483e-21}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eea70a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: np.float64(1.2623652522307264e-199),\n",
       " 0.1: np.float64(9.922264755770672e-200),\n",
       " 0.2: np.float64(7.719908795380786e-200),\n",
       " 0.30000000000000004: np.float64(5.939352956207508e-200),\n",
       " 0.4: np.float64(4.513566144459845e-200),\n",
       " 0.5: np.float64(3.383149847462046e-200),\n",
       " 0.6000000000000001: np.float64(2.4966225046927738e-200),\n",
       " 0.7000000000000001: np.float64(1.81068286216386e-200),\n",
       " 0.8: np.float64(1.287282791478903e-200),\n",
       " 0.9: np.float64(8.943332017481195e-201),\n",
       " 1.0: np.float64(6.0481356264385754e-201)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# |Get product over lambda probability across sampled construals\n",
    "lamda_inference = {}\n",
    "for curr_lambda, scene_info in p_lambda.items():\n",
    "    lamda_inference[curr_lambda] = np.prod([val for scene_name, construal_info in scene_info.items() for val in construal_info.values() if val > 0])\n",
    "lamda_inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuDrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
