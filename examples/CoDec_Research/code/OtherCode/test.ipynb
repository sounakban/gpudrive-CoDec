{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c91467d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-26 17:58:42.595607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748296722.613044  826034 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748296722.618022  826034 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748296722.632666  826034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748296722.632695  826034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748296722.632696  826034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748296722.632697  826034 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    }
   ],
   "source": [
    "# |Set parent to current working directory for imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive-CoDec':\n",
    "    working_dir = working_dir.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "sys.path.append(str(working_dir))\n",
    "\n",
    "# |Import everything\n",
    "from examples.CoDec_Research.code.pipelineOne.exp1_imports import *\n",
    "from examples.CoDec_Research.code.pipelineOne.exp1_config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e3f04",
   "metadata": {},
   "source": [
    "Test code for bayesian search over parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9623eeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default environment\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "################ SET EXP PARAMETERS ################\n",
    "####################################################\n",
    "\n",
    "\n",
    "# moving_veh_masks = get_mov_veh_masks(\n",
    "#                                     training_config=training_config, \n",
    "#                                     device=device, \n",
    "#                                     dataset_path=dataset_path,\n",
    "#                                     max_agents=moving_veh_count,\n",
    "#                                     result_file_loc=simulation_results_path,\n",
    "#                                     processID=processID\n",
    "#                                     )\n",
    "\n",
    "\n",
    "env_config, train_loader, env, sim_agent = get_gpuDrive_vars(\n",
    "                                                            training_config=training_config,\n",
    "                                                            device=device,\n",
    "                                                            num_parallel_envs=num_parallel_envs,\n",
    "                                                            dataset_path=dataset_path,\n",
    "                                                            total_envs=total_envs,\n",
    "                                                            sim_agent_path=\"daphne-cornelisse/policy_S10_000_02_27\",\n",
    "                                                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafc6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using construal values from file: examples/CoDec_Research/results/simulation_results/Set3_construal_vals_2025-05-26 16:12:39.716309.pickle\n"
     ]
    }
   ],
   "source": [
    "# |Check for saved construal utility values\n",
    "for srFile in simulation_results_files:\n",
    "    if \"construal_vals\" in srFile:\n",
    "        with open(srFile, 'rb') as opn_file:\n",
    "            default_values = pickle.load(opn_file)\n",
    "        #2# |Ensure the correct file is being loaded\n",
    "        if all(env_path2name(scene_path_) in default_values.keys() for scene_path_ in train_loader.dataset):\n",
    "            print(f\"Using construal values from file: {srFile}\")\n",
    "            break\n",
    "        else:\n",
    "            default_values = None\n",
    "if default_values is None:\n",
    "    raise FileNotFoundError(\"Could not find saved file for construal values for current scenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d7a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using log-likelihood dataframe from file: examples/CoDec_Research/results/simulation_results/Set3_log_likelihood_DF_rel_heading0.0_cardinality2.tsv\n"
     ]
    }
   ],
   "source": [
    "heuristic_params_str = '_'.join([heur_+str(param_) for heur_, param_ in heuristic_params.items()])\n",
    "\n",
    "for srFile in simulation_results_files:\n",
    "    if 'log_likelihood_DF' in srFile and heuristic_params_str in srFile and processID in srFile:\n",
    "        construal_likelihoods = pd.read_csv(srFile, sep='\\t')\n",
    "        construal_likelihoods['base_construal'] = construal_likelihoods['base_construal'].map(eval) # String to tuple\n",
    "        construal_likelihoods['test_construal'] = construal_likelihoods['test_construal'].map(eval) # String to tuple\n",
    "        print(f\"Using log-likelihood dataframe from file: {srFile}\")\n",
    "        break   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56347259",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'examples/CoDec_Research/results/simulation_results/Set3_construal_action_likelihoods_rel_heading0.0_cardinality2.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m srFile = \u001b[33m\"\u001b[39m\u001b[33mexamples/CoDec_Research/results/simulation_results/Set3_construal_action_likelihoods_rel_heading0.0_cardinality2.tsv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m construal_likelihoods = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# |Set up functions\u001b[39;00m\n\u001b[32m      5\u001b[39m get_constral_heurisrtic_values_partial = partial(get_constral_heurisrtic_values, env=env, \n\u001b[32m      6\u001b[39m                                                  train_loader=train_loader, default_values=default_values)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyEnvs/gpuDrive/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyEnvs/gpuDrive/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyEnvs/gpuDrive/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyEnvs/gpuDrive/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/PyEnvs/gpuDrive/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'examples/CoDec_Research/results/simulation_results/Set3_construal_action_likelihoods_rel_heading0.0_cardinality2.tsv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# |Set up functions\n",
    "get_constral_heurisrtic_values_partial = partial(get_constral_heurisrtic_values, env=env, \n",
    "                                                 train_loader=train_loader, default_values=default_values)\n",
    "target_param = \"rel_heading\"    # ego_distance or rel_heading\n",
    "curr_heuristic_params = deepcopy(heuristic_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d7c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.27it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.79it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  5.26it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.59it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  5.16it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  6.21it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  5.22it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.00it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  5.39it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: {'lambda_heur': np.float64(-4.023554998190569)}; f(x) = -1075.8979389566657.\n"
     ]
    }
   ],
   "source": [
    "# |Define the black box function to optimize.\n",
    "def black_box_function(lambda_heur):\n",
    "    flag = False\n",
    "    if isinstance(lambda_heur, list):\n",
    "        lambda_heur = lambda_heur[0]\n",
    "        flag = True\n",
    "    # |lambda_heur: hyper parameter to optimize for.\n",
    "    curr_heuristic_params[target_param] = lambda_heur\n",
    "    curr_heuristic_values = get_constral_heurisrtic_values_partial(heuristic_params=curr_heuristic_params)\n",
    "    # |Deep copy the dataframe them ke below changes\n",
    "    curr_construal_likelihoods = deepcopy(construal_likelihoods)\n",
    "    # |Convert log likelihoods to likelihoods\n",
    "    curr_construal_likelihoods['traj_constr_likelihoods'] = np.exp(-1*curr_construal_likelihoods['-log_likelihood'])\n",
    "    # |Get construal selection probs under lambda value\n",
    "    counstral_probs = [curr_heuristic_values[row['scene']][eval(row['test_construal'])] for _, row in curr_construal_likelihoods.iterrows()]\n",
    "    curr_construal_likelihoods['construal_probs'] = counstral_probs\n",
    "    # |Get likelihood for trajectories given construals\n",
    "    curr_construal_likelihoods['construal_likelihoods'] = curr_construal_likelihoods['construal_probs']*curr_construal_likelihoods['traj_constr_likelihoods']\n",
    "    # |Group by trajectory and add 'construal_likelihoods' values\n",
    "    traj_log_likelihoods = np.log(curr_construal_likelihoods.groupby(by=['scene','base_construal','sample']).sum()['construal_likelihoods'].to_list())\n",
    "    # |Take product of all likelihoods (log sum)\n",
    "    if flag:\n",
    "        return -1*traj_log_likelihoods.sum().item()\n",
    "    return traj_log_likelihoods.sum().item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# |Create a BayesianOptimization optimizer, and optimize the given black_box_function.\n",
    "pbounds = {\"lambda_heur\": [-15, 15]}    # Set range of lambda to optimize for.\n",
    "optimizer = BayesianOptimization(f = black_box_function,\n",
    "                                 pbounds = pbounds, verbose = 0,\n",
    "                                 random_state = 4)\n",
    "optimizer.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Best result: {}; f(x) = {}.\".format(optimizer.max[\"params\"], optimizer.max[\"target\"]))\n",
    "\n",
    "\n",
    "\n",
    "# # |Create a BayesianOptimization optimizer,\n",
    "# # |and optimize the given black_box_function.\n",
    "# from skopt import gp_minimize\n",
    "# from skopt.space import Real\n",
    "# pbounds = [Real(-15,15,name=\"lambda_heur\")]\n",
    "# res_gp = gp_minimize(black_box_function,\n",
    "#                         pbounds, n_calls = 15,\n",
    "#                         random_state = 4)\n",
    "# print(\"Best result: {}; f(x) = {}.\".format(res_gp.x, res_gp.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f81190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene</th>\n",
       "      <th>base_construal</th>\n",
       "      <th>test_construal</th>\n",
       "      <th>sample</th>\n",
       "      <th>-log_likelihood</th>\n",
       "      <th>likelihoods</th>\n",
       "      <th>traj_likelihoods</th>\n",
       "      <th>construal_probs</th>\n",
       "      <th>construal_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0</td>\n",
       "      <td>162.181710</td>\n",
       "      <td>3.676025e-71</td>\n",
       "      <td>3.676025e-71</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>2.325920e-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>0</td>\n",
       "      <td>121.318475</td>\n",
       "      <td>2.051425e-53</td>\n",
       "      <td>2.051425e-53</td>\n",
       "      <td>0.232411</td>\n",
       "      <td>4.767743e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>0</td>\n",
       "      <td>49.007218</td>\n",
       "      <td>5.205178e-22</td>\n",
       "      <td>5.205178e-22</td>\n",
       "      <td>0.255345</td>\n",
       "      <td>1.329118e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>0</td>\n",
       "      <td>75.987852</td>\n",
       "      <td>9.974596e-34</td>\n",
       "      <td>9.974596e-34</td>\n",
       "      <td>0.287765</td>\n",
       "      <td>2.870341e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>0</td>\n",
       "      <td>50.851837</td>\n",
       "      <td>8.228639e-23</td>\n",
       "      <td>8.228639e-23</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.595489e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(13,)</td>\n",
       "      <td>0</td>\n",
       "      <td>43.925818</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>3.237118e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(14,)</td>\n",
       "      <td>0</td>\n",
       "      <td>43.925818</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>1.105379e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(15,)</td>\n",
       "      <td>0</td>\n",
       "      <td>43.925818</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>0.162409</td>\n",
       "      <td>1.361034e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(16,)</td>\n",
       "      <td>0</td>\n",
       "      <td>43.925818</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>0.035137</td>\n",
       "      <td>2.944625e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>0</td>\n",
       "      <td>251.029711</td>\n",
       "      <td>9.531949e-110</td>\n",
       "      <td>9.531949e-110</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>1.469040e-112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          scene base_construal  \\\n",
       "0     tfrecord-00136-of-00150_6           (3,)   \n",
       "1     tfrecord-00136-of-00150_6           (3,)   \n",
       "2     tfrecord-00136-of-00150_6           (3,)   \n",
       "3     tfrecord-00136-of-00150_6           (3,)   \n",
       "4     tfrecord-00136-of-00150_6           (3,)   \n",
       "..                          ...            ...   \n",
       "763  tfrecord-00145-of-00150_75           (4,)   \n",
       "764  tfrecord-00145-of-00150_75           (4,)   \n",
       "765  tfrecord-00145-of-00150_75           (4,)   \n",
       "766  tfrecord-00145-of-00150_75           (4,)   \n",
       "767  tfrecord-00145-of-00150_75           (4,)   \n",
       "\n",
       "                                        test_construal  sample  \\\n",
       "0                                                 (1,)       0   \n",
       "1                                                 (2,)       0   \n",
       "2                                                 (3,)       0   \n",
       "3                                                 (4,)       0   \n",
       "4                                                 (5,)       0   \n",
       "..                                                 ...     ...   \n",
       "763                                              (13,)       0   \n",
       "764                                              (14,)       0   \n",
       "765                                              (15,)       0   \n",
       "766                                              (16,)       0   \n",
       "767  (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...       0   \n",
       "\n",
       "     -log_likelihood    likelihoods  traj_likelihoods  construal_probs  \\\n",
       "0         162.181710   3.676025e-71      3.676025e-71         0.006327   \n",
       "1         121.318475   2.051425e-53      2.051425e-53         0.232411   \n",
       "2          49.007218   5.205178e-22      5.205178e-22         0.255345   \n",
       "3          75.987852   9.974596e-34      9.974596e-34         0.287765   \n",
       "4          50.851837   8.228639e-23      8.228639e-23         0.001939   \n",
       "..               ...            ...               ...              ...   \n",
       "763        43.925818   8.380298e-20      8.380298e-20         0.003863   \n",
       "764        43.925818   8.380298e-20      8.380298e-20         0.001319   \n",
       "765        43.925818   8.380298e-20      8.380298e-20         0.162409   \n",
       "766        43.925818   8.380298e-20      8.380298e-20         0.035137   \n",
       "767       251.029711  9.531949e-110     9.531949e-110         0.001541   \n",
       "\n",
       "     construal_likelihoods  \n",
       "0             2.325920e-73  \n",
       "1             4.767743e-54  \n",
       "2             1.329118e-22  \n",
       "3             2.870341e-34  \n",
       "4             1.595489e-25  \n",
       "..                     ...  \n",
       "763           3.237118e-22  \n",
       "764           1.105379e-22  \n",
       "765           1.361034e-20  \n",
       "766           2.944625e-21  \n",
       "767          1.469040e-112  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_construal_likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c913e9",
   "metadata": {},
   "source": [
    "# Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f52164",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 17:11:01.013971: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747257061.024993  116797 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747257061.028320  116797 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747257061.036986  116797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747257061.037013  116797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747257061.037014  116797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747257061.037015  116797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default environment\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This part of pipeline 1 is dedicated to synthetic data generation. The code generates synthetic \n",
    "    data based on sampled construals (previous stage of pipeline).\n",
    "\"\"\"\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import cache\n",
    "from os import listdir\n",
    "import json\n",
    "import pickle\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import combinations\n",
    "\n",
    "from typing import Any, List, Tuple\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import dataclasses\n",
    "\n",
    "\n",
    "# |Set root for GPUDrive import\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from traitlets import default\n",
    "\n",
    "# Set working directory to the base directory 'gpudrive'\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive-CoDec':\n",
    "    working_dir = working_dir.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "sys.path.append(str(working_dir))\n",
    "\n",
    "\n",
    "# |GPUDrive imports\n",
    "from gpudrive.utils.config import load_config\n",
    "from examples.CoDec_Research.code.simulation.construal_main import generate_baseline_data, generate_selected_construal_traj, \\\n",
    "                                                                    get_constral_heurisrtic_values, generate_all_construal_trajnval\n",
    "from examples.CoDec_Research.code.gpuDrive_utils import get_gpuDrive_vars, save_pickle\n",
    "from examples.CoDec_Research.code.config import get_active_config\n",
    "\n",
    "\n",
    "# Function to extract filename from path\n",
    "env_path2name = lambda path: path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "# |START TIMER\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "####################################################\n",
    "################ SET EXP PARAMETERS ################\n",
    "####################################################\n",
    "\n",
    "curr_config = get_active_config()\n",
    "\n",
    "# Parameters for Inference\n",
    "heuristic_params = {\"ego_distance\": 0.5, \"cardinality\": 1}              # Hueristics and their weight parameters (to be inferred)\n",
    "\n",
    "construal_count_baseline = curr_config['construal_count_baseline']      # Number of construals to sample for baseline data generation\n",
    "trajectory_count_baseline = curr_config['trajectory_count_baseline']    # Number of baseline trajectories to generate per construal\n",
    "\n",
    "\n",
    "### Specify Environment Configuration ###\n",
    "\n",
    "# |Location to store (and retrieve pre-computed) simulation results\n",
    "simulation_results_path = \"examples/CoDec_Research/results/simulation_results/\"\n",
    "simulation_results_files = [simulation_results_path+fl_name for fl_name in listdir(simulation_results_path)]\n",
    "\n",
    "# |Model Config (on which model was trained)\n",
    "training_config = load_config(\"examples/experimental/config/reliable_agents_params\")\n",
    "\n",
    "# |Set scenario path\n",
    "dataset_path = 'data/processed/construal/Set1V/'\n",
    "processID = dataset_path.split('/')[-2]                 # Used for storing and retrieving relevant data\n",
    "\n",
    "# |Set simulator config\n",
    "max_agents = training_config.max_controlled_agents      # Get total vehicle count\n",
    "num_parallel_envs = curr_config['num_parallel_envs']\n",
    "total_envs = curr_config['total_envs']\n",
    "device = eval(curr_config['device'])\n",
    "\n",
    "# |Set construal config\n",
    "construal_size = 1\n",
    "observed_agents_count = max_agents - 1                              # Agents observed except self (used for vector sizes)\n",
    "sample_size_utility = curr_config['sample_size_utility']            # Number of samples to compute expected utility of a construal\n",
    "\n",
    "# |Other changes to variables\n",
    "training_config.max_controlled_agents = 1                           # Control only the first vehicle in the environment\n",
    "total_envs = min(total_envs, len(listdir(dataset_path)))\n",
    "\n",
    "\n",
    "env_config, train_loader, env, sim_agent = get_gpuDrive_vars(\n",
    "                                                            training_config=training_config,\n",
    "                                                            device=device,\n",
    "                                                            num_parallel_envs=num_parallel_envs,\n",
    "                                                            dataset_path=dataset_path,\n",
    "                                                            total_envs=total_envs,\n",
    "                                                            sim_agent_path=\"daphne-cornelisse/policy_S10_000_02_27\",\n",
    "                                                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7da679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# |Set root for GPUDrive import\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from traitlets import default\n",
    "import pickle\n",
    "\n",
    "# Set working directory to the base directory 'gpudrive'\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive-CoDec':\n",
    "    working_dir = working_dir.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "sys.path.append(str(working_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5446313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "srFile = \"examples/CoDec_Research/results/simulation_results/Set3_baseline_state_action_pairs_2025-05-13 15:33:50.425015.pickle\"\n",
    "with open(srFile, 'rb') as opn_file:\n",
    "    construal_action_likelihoods = pickle.load(opn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1298149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "srFile = \"examples/CoDec_Research/results/simulation_results/Set3_baseline_state_action_pairs_2025-05-14 00:56:25.396045.pickle\"\n",
    "with open(srFile, 'rb') as opn_file:\n",
    "    test_data = pickle.load(opn_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuDrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
