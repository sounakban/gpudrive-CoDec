{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c91467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# |Set parent to current working directory for imports\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive-CoDec':\n",
    "    working_dir = working_dir.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "sys.path.append(str(working_dir))\n",
    "\n",
    "# |Import everything\n",
    "from examples.CoDec_Research.code.shared_imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e3f04",
   "metadata": {},
   "source": [
    "Test code for bayesian search over parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623eeeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default environment\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "################ SET EXP PARAMETERS ################\n",
    "####################################################\n",
    "\n",
    "\n",
    "# moving_veh_masks = get_mov_veh_masks(\n",
    "#                                     training_config=training_config, \n",
    "#                                     device=device, \n",
    "#                                     dataset_path=dataset_path,\n",
    "#                                     max_agents=moving_veh_count,\n",
    "#                                     result_file_loc=simulation_results_path,\n",
    "#                                     processID=processID\n",
    "#                                     )\n",
    "\n",
    "\n",
    "env_config, train_loader, env, sim_agent = get_gpuDrive_vars(\n",
    "                                                            training_config=training_config,\n",
    "                                                            device=device,\n",
    "                                                            num_parallel_envs=num_parallel_envs,\n",
    "                                                            dataset_path=dataset_path,\n",
    "                                                            total_envs=total_envs,\n",
    "                                                            sim_agent_path=\"daphne-cornelisse/policy_S10_000_02_27\",\n",
    "                                                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dafc6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using construal values from file: examples/CoDec_Research/results/simulation_results/Set1V2_construal_vals_2025-05-14 19_27_40.072327.pickle\n"
     ]
    }
   ],
   "source": [
    "# |Function to extract filename from path\n",
    "env_path2name = lambda path: path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "# |Check for saved construal utility values\n",
    "for srFile in simulation_results_files:\n",
    "    if \"construal_vals\" in srFile:\n",
    "        with open(srFile, 'rb') as opn_file:\n",
    "            default_values = pickle.load(opn_file)\n",
    "        #2# |Ensure the correct file is being loaded\n",
    "        if all(env_path2name(scene_path_) in default_values.keys() for scene_path_ in train_loader.dataset):\n",
    "            print(f\"Using construal values from file: {srFile}\")\n",
    "            break\n",
    "        else:\n",
    "            default_values = None\n",
    "if default_values is None:\n",
    "    raise FileNotFoundError(\"Could not find saved file for construal values for current scenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56347259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from examples.CoDec_Research.code.simulation.construal_main import get_constral_heurisrtic_values\n",
    "from examples.CoDec_Research.code.config import heuristic_params\n",
    "\n",
    "srFile = \"examples/CoDec_Research/results/simulation_results/Set1V2_construal_action_likelihoods_rel_heading0.0_cardinality2.tsv\"\n",
    "construal_likelihoods = pd.read_csv(srFile, sep='\\t')\n",
    "\n",
    "# |Set up functions\n",
    "get_constral_heurisrtic_values_partial = partial(get_constral_heurisrtic_values, env=env, \n",
    "                                                 train_loader=train_loader, default_values=default_values)\n",
    "target_param = \"rel_heading\"    # ego_distance or rel_heading\n",
    "curr_heuristic_params = deepcopy(heuristic_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480d7c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.73it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.01it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.21it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.00it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.11it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.96it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: {'lambda_heur': np.float64(0.8887447830437398)}; f(x) = -4044.463588687572.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.94it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.18it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.98it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.91it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.02it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.04it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.88it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.13it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.02it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.23it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.09it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.93it/s]\n",
      "Processing Waymo batches: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best result: [0.8149378190946788]; f(x) = 4044.475307665715.\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "# | Tutorial: https://towardsdatascience.com/bayesian-optimization-with-python-85c66df711ec/\n",
    "\n",
    "# Define the black box function to optimize.\n",
    "def black_box_function(lambda_heur):\n",
    "    flag = False\n",
    "    if isinstance(lambda_heur, list):\n",
    "        lambda_heur = lambda_heur[0]\n",
    "        flag = True\n",
    "    # |lambda_heur: hyper parameter to optimize for.\n",
    "    curr_heuristic_params[target_param] = lambda_heur\n",
    "    curr_heuristic_values = get_constral_heurisrtic_values_partial(heuristic_params=curr_heuristic_params)\n",
    "    # |Deep copy the dataframe them ke below changes\n",
    "    curr_construal_likelihoods = deepcopy(construal_likelihoods)\n",
    "    # |Convert log likelihoods to likelihoods\n",
    "    curr_construal_likelihoods['traj_constr_likelihoods'] = np.exp(-1*curr_construal_likelihoods['-log_likelihood'])\n",
    "    # |Get construal selection probs under lambda value\n",
    "    counstral_probs = [curr_heuristic_values[row['scene']][eval(row['test_construal'])] for _, row in curr_construal_likelihoods.iterrows()]\n",
    "    curr_construal_likelihoods['construal_probs'] = counstral_probs\n",
    "    # |Get likelihood for trajectories given construals\n",
    "    curr_construal_likelihoods['construal_likelihoods'] = curr_construal_likelihoods['construal_probs']*curr_construal_likelihoods['traj_constr_likelihoods']\n",
    "    # |Group by trajectory and add 'construal_likelihoods' values\n",
    "    traj_log_likelihoods = np.log(curr_construal_likelihoods.groupby(by=['scene','base_construal','sample']).sum()['construal_likelihoods'].to_list())\n",
    "    # |Take product of all likelihoods (log sum)\n",
    "    if flag:\n",
    "        return -1*traj_log_likelihoods.sum().item()\n",
    "    return traj_log_likelihoods.sum().item()\n",
    "\n",
    "\n",
    "# Set range of C to optimize for.\n",
    "# bayes_opt requires this to be a dictionary.\n",
    "pbounds = {\"lambda_heur\": [-15, 15]}\n",
    "\n",
    "\n",
    "\n",
    "# Create a BayesianOptimization optimizer,\n",
    "# and optimize the given black_box_function.\n",
    "pbounds = {\"lambda_heur\": [-15, 15]}\n",
    "optimizer = BayesianOptimization(f = black_box_function,\n",
    "                                 pbounds = pbounds, verbose = 0,\n",
    "                                 random_state = 4)\n",
    "optimizer.maximize(init_points = 5, n_iter = 5)\n",
    "print(\"Best result: {}; f(x) = {}.\".format(optimizer.max[\"params\"], optimizer.max[\"target\"]))\n",
    "\n",
    "\n",
    "\n",
    "# Create a BayesianOptimization optimizer,\n",
    "# and optimize the given black_box_function.\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "pbounds = [Real(-15,15,name=\"lambda_heur\")]\n",
    "res_gp = gp_minimize(black_box_function,\n",
    "                        pbounds, n_calls = 15,\n",
    "                        random_state = 4)\n",
    "print(\"Best result: {}; f(x) = {}.\".format(res_gp.x, res_gp.fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f81190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scene</th>\n",
       "      <th>base_construal</th>\n",
       "      <th>test_construal</th>\n",
       "      <th>sample</th>\n",
       "      <th>-log_likelihood</th>\n",
       "      <th>likelihoods</th>\n",
       "      <th>traj_likelihoods</th>\n",
       "      <th>construal_probs</th>\n",
       "      <th>construal_likelihoods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>0</td>\n",
       "      <td>162.181710</td>\n",
       "      <td>3.676025e-71</td>\n",
       "      <td>3.676025e-71</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>2.325920e-73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(2,)</td>\n",
       "      <td>0</td>\n",
       "      <td>121.318475</td>\n",
       "      <td>2.051425e-53</td>\n",
       "      <td>2.051425e-53</td>\n",
       "      <td>0.232411</td>\n",
       "      <td>4.767743e-54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>0</td>\n",
       "      <td>49.007218</td>\n",
       "      <td>5.205178e-22</td>\n",
       "      <td>5.205178e-22</td>\n",
       "      <td>0.255345</td>\n",
       "      <td>1.329118e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>0</td>\n",
       "      <td>75.987852</td>\n",
       "      <td>9.974596e-34</td>\n",
       "      <td>9.974596e-34</td>\n",
       "      <td>0.287765</td>\n",
       "      <td>2.870341e-34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tfrecord-00136-of-00150_6</td>\n",
       "      <td>(3,)</td>\n",
       "      <td>(5,)</td>\n",
       "      <td>0</td>\n",
       "      <td>50.851837</td>\n",
       "      <td>8.228639e-23</td>\n",
       "      <td>8.228639e-23</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>1.595489e-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(13,)</td>\n",
       "      <td>0</td>\n",
       "      <td>43.925818</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>0.003863</td>\n",
       "      <td>3.237118e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(14,)</td>\n",
       "      <td>0</td>\n",
       "      <td>43.925818</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>1.105379e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(15,)</td>\n",
       "      <td>0</td>\n",
       "      <td>43.925818</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>0.162409</td>\n",
       "      <td>1.361034e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(16,)</td>\n",
       "      <td>0</td>\n",
       "      <td>43.925818</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>8.380298e-20</td>\n",
       "      <td>0.035137</td>\n",
       "      <td>2.944625e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>tfrecord-00145-of-00150_75</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>0</td>\n",
       "      <td>251.029711</td>\n",
       "      <td>9.531949e-110</td>\n",
       "      <td>9.531949e-110</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>1.469040e-112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          scene base_construal  \\\n",
       "0     tfrecord-00136-of-00150_6           (3,)   \n",
       "1     tfrecord-00136-of-00150_6           (3,)   \n",
       "2     tfrecord-00136-of-00150_6           (3,)   \n",
       "3     tfrecord-00136-of-00150_6           (3,)   \n",
       "4     tfrecord-00136-of-00150_6           (3,)   \n",
       "..                          ...            ...   \n",
       "763  tfrecord-00145-of-00150_75           (4,)   \n",
       "764  tfrecord-00145-of-00150_75           (4,)   \n",
       "765  tfrecord-00145-of-00150_75           (4,)   \n",
       "766  tfrecord-00145-of-00150_75           (4,)   \n",
       "767  tfrecord-00145-of-00150_75           (4,)   \n",
       "\n",
       "                                        test_construal  sample  \\\n",
       "0                                                 (1,)       0   \n",
       "1                                                 (2,)       0   \n",
       "2                                                 (3,)       0   \n",
       "3                                                 (4,)       0   \n",
       "4                                                 (5,)       0   \n",
       "..                                                 ...     ...   \n",
       "763                                              (13,)       0   \n",
       "764                                              (14,)       0   \n",
       "765                                              (15,)       0   \n",
       "766                                              (16,)       0   \n",
       "767  (1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...       0   \n",
       "\n",
       "     -log_likelihood    likelihoods  traj_likelihoods  construal_probs  \\\n",
       "0         162.181710   3.676025e-71      3.676025e-71         0.006327   \n",
       "1         121.318475   2.051425e-53      2.051425e-53         0.232411   \n",
       "2          49.007218   5.205178e-22      5.205178e-22         0.255345   \n",
       "3          75.987852   9.974596e-34      9.974596e-34         0.287765   \n",
       "4          50.851837   8.228639e-23      8.228639e-23         0.001939   \n",
       "..               ...            ...               ...              ...   \n",
       "763        43.925818   8.380298e-20      8.380298e-20         0.003863   \n",
       "764        43.925818   8.380298e-20      8.380298e-20         0.001319   \n",
       "765        43.925818   8.380298e-20      8.380298e-20         0.162409   \n",
       "766        43.925818   8.380298e-20      8.380298e-20         0.035137   \n",
       "767       251.029711  9.531949e-110     9.531949e-110         0.001541   \n",
       "\n",
       "     construal_likelihoods  \n",
       "0             2.325920e-73  \n",
       "1             4.767743e-54  \n",
       "2             1.329118e-22  \n",
       "3             2.870341e-34  \n",
       "4             1.595489e-25  \n",
       "..                     ...  \n",
       "763           3.237118e-22  \n",
       "764           1.105379e-22  \n",
       "765           1.361034e-20  \n",
       "766           2.944625e-21  \n",
       "767          1.469040e-112  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_construal_likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c913e9",
   "metadata": {},
   "source": [
    "# Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f52164",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-14 17:11:01.013971: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747257061.024993  116797 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747257061.028320  116797 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747257061.036986  116797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747257061.037013  116797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747257061.037014  116797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747257061.037015  116797 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[31mRuntimeError\u001b[39m: module compiled against ABI version 0x1000009 but this version of numpy is 0x2000000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized default environment\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This part of pipeline 1 is dedicated to synthetic data generation. The code generates synthetic \n",
    "    data based on sampled construals (previous stage of pipeline).\n",
    "\"\"\"\n",
    "\n",
    "from copy import deepcopy\n",
    "from functools import cache\n",
    "from os import listdir\n",
    "import json\n",
    "import pickle\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import combinations\n",
    "\n",
    "from typing import Any, List, Tuple\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import dataclasses\n",
    "\n",
    "\n",
    "# |Set root for GPUDrive import\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from traitlets import default\n",
    "\n",
    "# Set working directory to the base directory 'gpudrive'\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive-CoDec':\n",
    "    working_dir = working_dir.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "sys.path.append(str(working_dir))\n",
    "\n",
    "\n",
    "# |GPUDrive imports\n",
    "from gpudrive.utils.config import load_config\n",
    "from examples.CoDec_Research.code.simulation.construal_main import generate_baseline_data, generate_selected_construal_traj, \\\n",
    "                                                                    get_constral_heurisrtic_values, generate_all_construal_trajnval\n",
    "from examples.CoDec_Research.code.gpuDrive_utils import get_gpuDrive_vars, save_pickle\n",
    "from examples.CoDec_Research.code.config import get_active_config\n",
    "\n",
    "\n",
    "# Function to extract filename from path\n",
    "env_path2name = lambda path: path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "# |START TIMER\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "####################################################\n",
    "################ SET EXP PARAMETERS ################\n",
    "####################################################\n",
    "\n",
    "curr_config = get_active_config()\n",
    "\n",
    "# Parameters for Inference\n",
    "heuristic_params = {\"ego_distance\": 0.5, \"cardinality\": 1}              # Hueristics and their weight parameters (to be inferred)\n",
    "\n",
    "construal_count_baseline = curr_config['construal_count_baseline']      # Number of construals to sample for baseline data generation\n",
    "trajectory_count_baseline = curr_config['trajectory_count_baseline']    # Number of baseline trajectories to generate per construal\n",
    "\n",
    "\n",
    "### Specify Environment Configuration ###\n",
    "\n",
    "# |Location to store (and retrieve pre-computed) simulation results\n",
    "simulation_results_path = \"examples/CoDec_Research/results/simulation_results/\"\n",
    "simulation_results_files = [simulation_results_path+fl_name for fl_name in listdir(simulation_results_path)]\n",
    "\n",
    "# |Model Config (on which model was trained)\n",
    "training_config = load_config(\"examples/experimental/config/reliable_agents_params\")\n",
    "\n",
    "# |Set scenario path\n",
    "dataset_path = 'data/processed/construal/Set1V/'\n",
    "processID = dataset_path.split('/')[-2]                 # Used for storing and retrieving relevant data\n",
    "\n",
    "# |Set simulator config\n",
    "max_agents = training_config.max_controlled_agents      # Get total vehicle count\n",
    "num_parallel_envs = curr_config['num_parallel_envs']\n",
    "total_envs = curr_config['total_envs']\n",
    "device = eval(curr_config['device'])\n",
    "\n",
    "# |Set construal config\n",
    "construal_size = 1\n",
    "observed_agents_count = max_agents - 1                              # Agents observed except self (used for vector sizes)\n",
    "sample_size_utility = curr_config['sample_size_utility']            # Number of samples to compute expected utility of a construal\n",
    "\n",
    "# |Other changes to variables\n",
    "training_config.max_controlled_agents = 1                           # Control only the first vehicle in the environment\n",
    "total_envs = min(total_envs, len(listdir(dataset_path)))\n",
    "\n",
    "\n",
    "env_config, train_loader, env, sim_agent = get_gpuDrive_vars(\n",
    "                                                            training_config=training_config,\n",
    "                                                            device=device,\n",
    "                                                            num_parallel_envs=num_parallel_envs,\n",
    "                                                            dataset_path=dataset_path,\n",
    "                                                            total_envs=total_envs,\n",
    "                                                            sim_agent_path=\"daphne-cornelisse/policy_S10_000_02_27\",\n",
    "                                                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d7da679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# |Set root for GPUDrive import\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from traitlets import default\n",
    "import pickle\n",
    "\n",
    "# Set working directory to the base directory 'gpudrive'\n",
    "working_dir = Path.cwd()\n",
    "while working_dir.name != 'gpudrive-CoDec':\n",
    "    working_dir = working_dir.parent\n",
    "    if working_dir == Path.home():\n",
    "        raise FileNotFoundError(\"Base directory 'gpudrive' not found\")\n",
    "os.chdir(working_dir)\n",
    "sys.path.append(str(working_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5446313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "srFile = \"examples/CoDec_Research/results/simulation_results/Set3_baseline_state_action_pairs_2025-05-13 15:33:50.425015.pickle\"\n",
    "with open(srFile, 'rb') as opn_file:\n",
    "    construal_action_likelihoods = pickle.load(opn_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a1298149",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "srFile = \"examples/CoDec_Research/results/simulation_results/Set3_baseline_state_action_pairs_2025-05-14 00:56:25.396045.pickle\"\n",
    "with open(srFile, 'rb') as opn_file:\n",
    "    test_data = pickle.load(opn_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuDrive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
