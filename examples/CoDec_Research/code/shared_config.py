

# |Shared Imports
from examples.CoDec_Research.code.shared_imports import *


#################################
### EXPERIMENT CONFIGURATIONS ###
#################################

# |Function called from scripts to get the configuration currently being used
def get_active_config():
    active_config = server_config
    active_config.update(shared_config)  # Update with shared config parameters
    return active_config




# |Shared configurations for the experiment, that do not change
shared_config = {
                'simulation_results_path': 'examples/CoDec_Research/results/simulation_results/',
                'save_intermediate_files': False,       # If set to False, files apart from construal values and final results are not 
                                                        #   saved. If True, everything is saved
                'intermediate_file_location': 'temp/',  # Location to save intermediate files
                'compress_synthetic_data': True,        # If set to True, synthetic data is compressed before saving
                'lambda_distribution': False,           # Set to True if you want to get probability distribution over lambda values, 
                                                        #   False if you want to optimize lambda value
                'ego_in_construal': False,              # Boolean flag indicating whether to keep ego in construals. 
                                                        #   Ego is observed anyway
                }


# |Configuration for running full pipeline locally on PC CPU
local_config = {
                'dataset_path': 'data/processed/construal/Set3/',         # Path to scenario files
                'construal_size': 1,
                'num_parallel_envs': 3,
                'num_parallel_envs_light': 3,                             # Number of parallel environments for memory intensive operations
                'total_envs': 3,
                'device': "'cpu'",
                'sample_size_utility': 1,                                 # Number of samples per construal to compute behavioral utility of construals
                'construal_count_baseline': 4,                            # Number of construals to sample (per scene) for baseline data generation
                'trajectory_count_baseline': 1,                           # Number of baseline trajectories to generate per construal
                }


# |Configuration for running inference logic locally on PC CPU based on data generated by server
local_config_2= {# |run inference on baseline data already generated on the server
                'dataset_path': 'data/processed/construal/Set1V2/',         # Path to scenario files
                'construal_size': 1,
                'num_parallel_envs': 10,
                'num_parallel_envs_light': 5,                             # Number of parallel environments for memory intensive operations
                'total_envs': 10,
                'device': "'cpu'",
                'sample_size_utility': 4,                                 # Number of samples per construal to compute behavioral utility of construals
                'construal_count_baseline': 8,                            # Number of construals to sample (per scene) for baseline data generation
                'trajectory_count_baseline': 1,                           # Number of baseline trajectories to generate per construal
                }



# |Configuration for running full pipeline locally on GPU Server
server_config = {
                'dataset_path': 'data/processed/construal/Set1V2/',         # Path to scenario files
                'construal_size': 1,
                'num_parallel_envs': 10,
                'num_parallel_envs_light': 5,                             # Number of parallel environments for memory intensive operations
                'total_envs': 10,
                'device': "'cuda' if torch.cuda.is_available() else 'cpu'",
                'sample_size_utility': 5,                                # Number of samples per construal to compute behavioral utility of construals
                'construal_count_baseline': 2,                            # Number of construals to sample (per scene) for baseline data generation
                'trajectory_count_baseline': 1,                           # Number of baseline trajectories to generate per construal
                }





################################
### HEURISTICS CONFIGURATION ###
################################

param_val_sampling_rate = 31

# |Dictionary specifying the range of weights for each heuristic
heuristic_params_vals = {  
                        "cardinality": np.linspace(0,10,param_val_sampling_rate),
                        "ego_distance": np.linspace(0,10,param_val_sampling_rate),
                        "dev_ego_heading": np.linspace(-15,15,param_val_sampling_rate), # Working range: -5,5
                        "rel_heading": np.linspace(-15,15,param_val_sampling_rate),     # Working range: -5, 5
                        "dev_collission": np.linspace(-20,20,param_val_sampling_rate),  # Working range: -15, 2
                        }

# |Hueristics values used for generating the synthetic data
# active_heuristic_params = { "ego_distance": ego_dis_param_values[5],            # Hueristics and their weight parameters (to be inferred)
#                             "dev_ego_heading": ego_head_param_values[1],
#                             "cardinality": 1}

# |Hueristics values used for generating the synthetic data
active_heuristic_params = {            
                            "cardinality": 2,
                            "ego_distance": 0,
                            "dev_ego_heading": 0,
                            "rel_heading": 0,
                            "dev_collission": 0,
                            # "dev_collission": heuristic_params_vals['dev_collission'][19],
                            }